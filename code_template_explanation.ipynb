{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGv2NA1zntFNrqp/OgmAM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation/blob/main/code_template_explanation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task\n",
        "\n",
        "We were given InkML files, which contain metadata and a list of strokes: [(0,0),(1;0)]...  \n",
        "These are on-line handwritten mathematical expressions, we'll try to recognize them via LG(Labelled Graph) as output.  \n",
        "This is the sequence of actions performed:  \n",
        "1) Determine possible stroke combinations.  \n",
        "2) Remove impossible combinations with a classifier.  \n",
        "3) Convert each combination to a symbol.  \n",
        "\n",
        "We'll handle spatial relations later  \n",
        "We'll also handle the final decision later, but we can add a grammar or language model at that point, "
      ],
      "metadata": {
        "id": "aWuEiNtvzSKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment setup"
      ],
      "metadata": {
        "id": "B9M5CzAi6gbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting project files"
      ],
      "metadata": {
        "id": "YtP6_syxzN5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be importing the project files from our github repository."
      ],
      "metadata": {
        "id": "aYodzelc6zQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation.git"
      ],
      "metadata": {
        "id": "jSZh0T12tA6_",
        "outputId": "d3122cb1-ddd2-4d6a-d9ed-e461eaacdd19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Master_2_MLVC_Recognize_Handwritten_Equation'...\n",
            "remote: Enumerating objects: 119843, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 119843 (delta 71), reused 95 (delta 39), pack-reused 119711\u001b[K\n",
            "Receiving objects: 100% (119843/119843), 46.53 MiB | 17.70 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Checking out files: 100% (209489/209489), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Master_2_MLVC_Recognize_Handwritten_Equation/code"
      ],
      "metadata": {
        "id": "8fBivD4utpW2",
        "outputId": "b3cd228f-c7fb-43c2-ad31-ef14b5db5834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Master_2_MLVC_Recognize_Handwritten_Equation/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first show what each script does, and how to interpret their output, then we will show how to use the evaluation scripts, and finally detail how each script functions."
      ],
      "metadata": {
        "id": "TWeYcdlM98vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data to train our classifiers\n",
        "\n",
        "[This](https://uncloud.univ-nantes.fr/index.php/s/OdAtErZgxKGjsNy) contains a bunch of symbols (in datasymbol_iso/) and expressions (in FullExpressions/) to help train our future classifiers.\n",
        "\n"
      ],
      "metadata": {
        "id": "DBWRfdGJNWoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Showcasing parts of code"
      ],
      "metadata": {
        "id": "1UbhDK12FT-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### segmenter.py explanation\n",
        "\n",
        "The first action is to collect the possible stroke combinations, for now we'll simply take every consecutive stroke combinations.  \n",
        "So if we have 4 strokes in one inkml file, 13 combinations can be done.  \n",
        "\n",
        "Each line of the output corresponds to a hypothesis: indicating the symbol type, the symbol with index (starting with 1, but dummy value for now since we don't know what symbol the combination could be), then the symbol without index, then the supposed confidence of the model. We also have the strokes used next to these informations.\n",
        "\n",
        "At this point, this can be optimized by already removed hypotheses take don't make sense, for instance trying to make a symbol with every single stroke is highly irregular and shouldn't happen, so we could remove that combination before calling the other scripts.\n",
        "\n",
        "The ground truth for the segmentation is available in the original lg files, since the strokes used are listed next to each symbol."
      ],
      "metadata": {
        "id": "YF6s8x3azFFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmenter.py -i ../data/formulaire001-equation001.inkml -o ../data/example.lg"
      ],
      "metadata": {
        "id": "6dPWrT0DBnCO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmenter.py -i ../data/formulaire001-equation001.inkml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV6ZMCZfP_Z2",
        "outputId": "eb3d0599-f70f-483b-f593-ed682dead159"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O,hyp0,*,1.0,0\n",
            "O,hyp1,*,1.0,1\n",
            "O,hyp2,*,1.0,2\n",
            "O,hyp3,*,1.0,3\n",
            "O,hyp4,*,1.0,4\n",
            "O,hyp5,*,1.0,0,1\n",
            "O,hyp6,*,1.0,1,2\n",
            "O,hyp7,*,1.0,2,3\n",
            "O,hyp8,*,1.0,3,4\n",
            "O,hyp9,*,1.0,0,1,2\n",
            "O,hyp10,*,1.0,1,2,3\n",
            "O,hyp11,*,1.0,2,3,4\n",
            "O,hyp12,*,1.0,0,1,2,3\n",
            "O,hyp13,*,1.0,1,2,3,4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we've said earlier, we simply keep every consecutive stroke combination as our possible hypotheses."
      ],
      "metadata": {
        "id": "wJBIb_1W7-E_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Git stuff"
      ],
      "metadata": {
        "id": "ScFP0M3SG8HL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git stash\n",
        "#!git stash drop"
      ],
      "metadata": {
        "id": "hhzXOe_FXkkE",
        "outputId": "ab97a893-0bf0-452f-fbe3-2ec4132ee598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No local changes to save\n",
            "No stash entries found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git reset --soft HEAD^ "
      ],
      "metadata": {
        "id": "cKE7XoYNduo9"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1pRK30bFP7a",
        "outputId": "6d534425-9d94-4db3-9176-dcd9cb72c7e1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects:  12% (1/8)\u001b[K\rremote: Counting objects:  25% (2/8)\u001b[K\rremote: Counting objects:  37% (3/8)\u001b[K\rremote: Counting objects:  50% (4/8)\u001b[K\rremote: Counting objects:  62% (5/8)\u001b[K\rremote: Counting objects:  75% (6/8)\u001b[K\rremote: Counting objects:  87% (7/8)\u001b[K\rremote: Counting objects: 100% (8/8)\u001b[K\rremote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects:  20% (1/5)\u001b[K\rremote: Compressing objects:  40% (2/5)\u001b[K\rremote: Compressing objects:  60% (3/5)\u001b[K\rremote: Compressing objects:  80% (4/5)\u001b[K\rremote: Compressing objects: 100% (5/5)\u001b[K\rremote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 6 (delta 3), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects:  16% (1/6)   \rUnpacking objects:  33% (2/6)   \rUnpacking objects:  50% (3/6)   \rUnpacking objects:  66% (4/6)   \rUnpacking objects:  83% (5/6)   \rUnpacking objects: 100% (6/6)   \rUnpacking objects: 100% (6/6), done.\n",
            "From https://github.com/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation\n",
            "   357bb3271..924dee090  main       -> origin/main\n",
            "Updating dc38065c7..924dee090\n",
            "Fast-forward\n",
            " code_template_explanation.ipynb | 396 \u001b[32m++++++++++++++++++++++++\u001b[m\u001b[31m----------------\u001b[m\n",
            " scores_segmentSelector.csv      |   2 \u001b[32m+\u001b[m\n",
            " 2 files changed, 236 insertions(+), 162 deletions(-)\n",
            " create mode 100644 scores_segmentSelector.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git config --global user.email \"XXX@gmail.com\"\n",
        "#!git config --global user.name \"XXX\""
      ],
      "metadata": {
        "id": "ODIimJvfFfov"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "bCpa1mjKc4L3"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Speed up inference for segmentReco\""
      ],
      "metadata": {
        "id": "yX9WK8T8c6FW",
        "outputId": "8bc98309-19a2-4bdd-8233-cec6c54312cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 3349bd494] Speed up inference for segmentReco\n",
            " 7 files changed, 24 insertions(+), 272 deletions(-)\n",
            " delete mode 100644 code/CROHME-train-iso.py\n",
            " create mode 100644 code/graph_train_segmentReco.png\n",
            " rewrite code/output.png (99%)\n",
            " rewrite code/resultMLP.png (99%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push https://hiddentoken@github.com/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation.git"
      ],
      "metadata": {
        "id": "9uUZDwxbdA9Q",
        "outputId": "f4ffa291-aa9c-49ac-a0fb-4fa67592b7cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting objects: 9, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  11% (1/9)   \rCompressing objects:  22% (2/9)   \rCompressing objects:  33% (3/9)   \rCompressing objects:  44% (4/9)   \rCompressing objects:  55% (5/9)   \rCompressing objects:  66% (6/9)   \rCompressing objects:  77% (7/9)   \rCompressing objects:  88% (8/9)   \rCompressing objects: 100% (9/9)   \rCompressing objects: 100% (9/9), done.\n",
            "Writing objects:  11% (1/9)   \rWriting objects:  22% (2/9)   \rWriting objects:  33% (3/9)   \rWriting objects:  44% (4/9)   \rWriting objects:  55% (5/9)   \rWriting objects:  66% (6/9)   \rWriting objects:  77% (7/9)   \rWriting objects:  88% (8/9)   \rWriting objects: 100% (9/9)   \rWriting objects: 100% (9/9), 63.01 KiB | 21.00 MiB/s, done.\n",
            "Total 9 (delta 5), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (5/5), completed with 5 local objects.\u001b[K\n",
            "To https://github.com/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation.git\n",
            "   924dee090..3349bd494  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CROHME_train_segmentSelector.py & segmentSelect.py explanation"
      ],
      "metadata": {
        "id": "JjTmdp150a1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we use neural networks in our overall process as our classifiers/predictors, they need to be trained beforehand. But let's first explain what we're trying to do in this part of the process:  \n",
        "\n",
        "The script 'segmentSelect.py' takes as input the initial inkml file, alongside the \"prototype\" lg file: We combine the stroke combinations from the prototype file alongside the inkml stroke data to generate images, then we check whether these images make sense as a symbol, no matter the context.  \n",
        "This is a classification problem with two possible outputs : Image is valid or invalid.  \n",
        "We also check the confidence value of the model with a threshold in order to ignore unsure hypotheses, which should boost accuracy somewhat.\n",
        "\n",
        "Now, for the training part, while we could simply store the weights of the models and import them, we still want to show the specifics of our training due to the characteristics of our data:\n",
        "\n",
        "While training the model batch per batch, we make sure that each of these batches contain an representative random subset of the original data, since we have a lot less invalid images for training than valid images, while still trying to make sure that the model doesn't excessively consider valid images.  \n",
        "The rest of the training logic is quite normal, the state of the model is saved whenever we achieve a new validation loss low, and we implemented early stopping to prevent overfitting."
      ],
      "metadata": {
        "id": "3GpG0BAV0c3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 CROHME_train_segmentSelector.py"
      ],
      "metadata": {
        "id": "DBL3xPInG-uD",
        "outputId": "58704577-8d55-4849-9c17-f51946f1df56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "('invalid', 'valid')\n",
            "nb classes 2 , training size 12000, val size 4000, test size 4000\n",
            "valid invalid valid invalid\n",
            "AlexNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4), bias=False)\n",
            "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(96, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 1 batch  1000 \n",
            "Train loss : 0.075\n",
            "Validation loss mean : 0.066\n",
            "Epoch 1 of 10 took 34.348s\n",
            "Epoch 2 batch   500 \n",
            "Train loss : 0.061\n",
            "Validation loss mean : 0.062\n",
            "Epoch 2 batch  1500 \n",
            "Train loss : 0.060\n",
            "Validation loss mean : 0.059\n",
            "Epoch 2 of 10 took 36.663s\n",
            "Epoch 3 batch  1000 \n",
            "Train loss : 0.056\n",
            "Validation loss mean : 0.058\n",
            "Epoch 3 of 10 took 32.161s\n",
            "Epoch 4 batch   500 \n",
            "Train loss : 0.053\n",
            "Validation loss mean : 0.055\n",
            "Epoch 4 batch  1500 \n",
            "Train loss : 0.050\n",
            "Validation loss mean : 0.056\n",
            "Epoch 4 of 10 took 34.357s\n",
            "Epoch 5 batch  1000 \n",
            "Train loss : 0.046\n",
            "Validation loss mean : 0.055\n",
            "Epoch 5 of 10 took 35.000s\n",
            "Epoch 6 batch   500 \n",
            "Train loss : 0.044\n",
            "Validation loss mean : 0.055\n",
            "Epoch 6 batch  1500 \n",
            "Train loss : 0.042\n",
            "Validation loss mean : 0.055\n",
            "Epoch 6 of 10 took 35.173s\n",
            "Epoch 7 batch  1000 \n",
            "Train loss : 0.037\n",
            "Validation loss mean : 0.056\n",
            "Epoch 7 of 10 took 22.126s\n",
            "Warning: current epoch stopped early due to early stopping strategy\n",
            "Finished Training\n",
            "GroundTruth:  invalid invalid valid valid valid valid invalid invalid\n",
            "Predicted:  invalid invalid valid valid valid valid invalid valid\n",
            "Accuracy of the network on the test images: 79 %\n",
            "Accuracy of invalid : 77 % (1524/1961)\n",
            "Accuracy of valid : 81 % (1666/2039)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### segmentSelect.py example"
      ],
      "metadata": {
        "id": "m3W6Q2QxzNlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmentSelect.py -o ../data/example2.lg ../data/formulaire001-equation001.inkml ../data/example.lg "
      ],
      "metadata": {
        "id": "pv0w5wivD61i"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmentSelect.py ../data/formulaire001-equation001.inkml ../data/example.lg "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y60IqgVQBhP",
        "outputId": "cde551bf-cdb6-4f77-eb87-f6c4c2f98424"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O,hyp7,*,0.509894073009491,2,3\n",
            "O,hyp8,*,0.9908795356750488,3,4\n",
            "O,hyp10,*,0.7905758023262024,1,2,3\n",
            "O,hyp12,*,0.7709046602249146,0,1,2,3\n",
            "O,hyp13,*,0.6058663725852966,1,2,3,4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script takes as input the initial inkml file, alongside the \"prototype\" lg file: We combine the stroke combinations alongside the inkml data to generate images, then we check whether these make sense as a symbol, no matter the context.\n",
        "\n",
        "For now this simply gives a fully random probability that the images are valid symbols.\n",
        "\n",
        "Need to change two things in there, first adding a classifier to check the validity of supposed symbols,  \n",
        "then change the threshold based on empirical evidence or what I feel like at the time."
      ],
      "metadata": {
        "id": "1xt9xpt3FvIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### segmentReco.py explanation"
      ],
      "metadata": {
        "id": "b0AIEfy9CsB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 CROHME_train_segmentReco.py"
      ],
      "metadata": {
        "id": "-yudklZ1Kp5v",
        "outputId": "ab13e998-4bbb-4cdc-b6d6-1c5977c201d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "['theta', 'n', 'w', 'z', 'S_', 'x', 'h', ')', 'dot', 'beta', 'gamma', 's', 'd', '+', 'm', '1', 'V_', '9', 'sqrt', '}', 'rightarrow', 'r', 'b', 'F_', 'u', 't', 'leq', 'tan', 'sin', 'alpha', 'exists', 'div', 'A_', 'pipe', '(', 'H_', 'i', 'o', '3', 'forall', 'N_', 'times', 'M_', 'E_', 'Delta', 'lambda', 'L_', 'neq', 'c', ',', 'a', '5', 'q', 'R_', '0', 'Y_', 'sum', 'div_op', '[', 'log', '8', 'C_', 'lim', 'j', '4', 'lt', 'infty', 'pm', '=', 'sigma', 'phi', 'I_', 'gt', 'G_', 'cos', 'prime', '2', 'p', 'B_', 'geq', 'in', 'v', ']', 'k', 'l', '{', 'ldots', 'P_', '6', 'int', 'pi', 'g', 'mu', 'T_', 'e', '!', 'X_', 'y', 'f', '-', '7']\n",
            "nb classes 101 , training size 6000, val size 2000, test size 2000\n",
            "theta     w     z theta\n",
            "AlexNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4), bias=False)\n",
            "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(96, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=101, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 1 of 10 took 17.067s\n",
            "Epoch 2 batch   250 \n",
            "Train loss : 0.075\n",
            "Validation loss mean : 0.011\n",
            "Epoch 2 of 10 took 16.060s\n",
            "Epoch 3 batch   500 \n",
            "Train loss : 0.008\n",
            "Validation loss mean : 0.005\n",
            "Epoch 3 of 10 took 15.779s\n",
            "Epoch 4 batch   750 \n",
            "Train loss : 0.004\n",
            "Validation loss mean : 0.005\n",
            "Epoch 4 of 10 took 15.788s\n",
            "Epoch 5 of 10 took 14.696s\n",
            "Epoch 6 batch   250 \n",
            "Train loss : 0.003\n",
            "Validation loss mean : 0.004\n",
            "Epoch 6 of 10 took 15.871s\n",
            "Epoch 7 batch   500 \n",
            "Train loss : 0.003\n",
            "Validation loss mean : 0.003\n",
            "Epoch 7 of 10 took 15.783s\n",
            "Epoch 8 batch   750 \n",
            "Train loss : 0.001\n",
            "Validation loss mean : 0.003\n",
            "Epoch 8 of 10 took 15.753s\n",
            "Epoch 9 of 10 took 14.548s\n",
            "Epoch 10 batch   250 \n",
            "Train loss : 0.002\n",
            "Validation loss mean : 0.002\n",
            "Epoch 10 of 10 took 15.941s\n",
            "Finished Training\n",
            "GroundTruth:      w     w     n     z     w     w     w     w\n",
            "Predicted:  tensor(2, device='cuda:0') tensor(2, device='cuda:0')     n tensor(3, device='cuda:0') tensor(2, device='cuda:0') tensor(2, device='cuda:0') tensor(2, device='cuda:0') tensor(2, device='cuda:0')\n",
            "Accuracy of the network on the test images: 99 %\n",
            "Accuracy of theta : 96 % (25/26)\n",
            "Accuracy of     n : 99 % (774/777)\n",
            "Accuracy of     w : 99 % (779/781)\n",
            "Accuracy of     z : 99 % (413/416)\n",
            "No    S_ sample\n",
            "No     x sample\n",
            "No     h sample\n",
            "No     ) sample\n",
            "No   dot sample\n",
            "No  beta sample\n",
            "No gamma sample\n",
            "No     s sample\n",
            "No     d sample\n",
            "No     + sample\n",
            "No     m sample\n",
            "No     1 sample\n",
            "No    V_ sample\n",
            "No     9 sample\n",
            "No  sqrt sample\n",
            "No     } sample\n",
            "No rightarrow sample\n",
            "No     r sample\n",
            "No     b sample\n",
            "No    F_ sample\n",
            "No     u sample\n",
            "No     t sample\n",
            "No   leq sample\n",
            "No   tan sample\n",
            "No   sin sample\n",
            "No alpha sample\n",
            "No exists sample\n",
            "No   div sample\n",
            "No    A_ sample\n",
            "No  pipe sample\n",
            "No     ( sample\n",
            "No    H_ sample\n",
            "No     i sample\n",
            "No     o sample\n",
            "No     3 sample\n",
            "No forall sample\n",
            "No    N_ sample\n",
            "No times sample\n",
            "No    M_ sample\n",
            "No    E_ sample\n",
            "No Delta sample\n",
            "No lambda sample\n",
            "No    L_ sample\n",
            "No   neq sample\n",
            "No     c sample\n",
            "No     , sample\n",
            "No     a sample\n",
            "No     5 sample\n",
            "No     q sample\n",
            "No    R_ sample\n",
            "No     0 sample\n",
            "No    Y_ sample\n",
            "No   sum sample\n",
            "No div_op sample\n",
            "No     [ sample\n",
            "No   log sample\n",
            "No     8 sample\n",
            "No    C_ sample\n",
            "No   lim sample\n",
            "No     j sample\n",
            "No     4 sample\n",
            "No    lt sample\n",
            "No infty sample\n",
            "No    pm sample\n",
            "No     = sample\n",
            "No sigma sample\n",
            "No   phi sample\n",
            "No    I_ sample\n",
            "No    gt sample\n",
            "No    G_ sample\n",
            "No   cos sample\n",
            "No prime sample\n",
            "No     2 sample\n",
            "No     p sample\n",
            "No    B_ sample\n",
            "No   geq sample\n",
            "No    in sample\n",
            "No     v sample\n",
            "No     ] sample\n",
            "No     k sample\n",
            "No     l sample\n",
            "No     { sample\n",
            "No ldots sample\n",
            "No    P_ sample\n",
            "No     6 sample\n",
            "No   int sample\n",
            "No    pi sample\n",
            "No     g sample\n",
            "No    mu sample\n",
            "No    T_ sample\n",
            "No     e sample\n",
            "No     ! sample\n",
            "No    X_ sample\n",
            "No     y sample\n",
            "No     f sample\n",
            "No     - sample\n",
            "No     7 sample\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 symbolReco.py -o ../data/example3.lg ../data/formulaire001-equation001.inkml ../data/example2.lg"
      ],
      "metadata": {
        "id": "duC2zf_nHfmu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 symbolReco.py ../data/formulaire001-equation001.inkml ../data/example2.lg"
      ],
      "metadata": {
        "id": "AUa4PEpbO0G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### selectBestSeg.py explanation"
      ],
      "metadata": {
        "id": "OLES8XcSOyo4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9l4K5-vkOx72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating"
      ],
      "metadata": {
        "id": "CojBtaQYNZg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "use lgeval and show some tables and graphics."
      ],
      "metadata": {
        "id": "MhmMbfUoNdX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODOLIST: check that everything works: X  \n",
        "Apply evaluation script (import relevant things here): X  \n",
        "Nitpick a bunch of things:  X  \n",
        "Write some things on notebook: X  \n"
      ],
      "metadata": {
        "id": "lXmV8VSIvP3q"
      }
    }
  ]
}