{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNInuEwSGQWT1eBKUKFVFOT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation/blob/main/code_template_explanation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task\n",
        "\n",
        "We were given InkML files, which contain metadata and a list of strokes: [(0,0),(1;0)]...  \n",
        "These are on-line handwritten mathematical expressions, we'll try to recognize them via LG(Labelled Graph) as output.  \n",
        "This is the sequence of actions performed:  \n",
        "1) Determine possible stroke combinations.  \n",
        "2) Remove impossible combinations with a classifier.  \n",
        "3) Convert each combination to a symbol.  \n",
        "\n",
        "We'll handle spatial relations later  \n",
        "We'll also handle the final decision later, but we can add a grammar or language model at that point, "
      ],
      "metadata": {
        "id": "aWuEiNtvzSKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment setup"
      ],
      "metadata": {
        "id": "B9M5CzAi6gbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting project files"
      ],
      "metadata": {
        "id": "YtP6_syxzN5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be importing the project files from our github repository."
      ],
      "metadata": {
        "id": "aYodzelc6zQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation.git"
      ],
      "metadata": {
        "id": "jSZh0T12tA6_",
        "outputId": "d3122cb1-ddd2-4d6a-d9ed-e461eaacdd19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Master_2_MLVC_Recognize_Handwritten_Equation'...\n",
            "remote: Enumerating objects: 119843, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 119843 (delta 71), reused 95 (delta 39), pack-reused 119711\u001b[K\n",
            "Receiving objects: 100% (119843/119843), 46.53 MiB | 17.70 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "Checking out files: 100% (209489/209489), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Master_2_MLVC_Recognize_Handwritten_Equation/code"
      ],
      "metadata": {
        "id": "8fBivD4utpW2",
        "outputId": "b3cd228f-c7fb-43c2-ad31-ef14b5db5834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Master_2_MLVC_Recognize_Handwritten_Equation/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first show what each script does, and how to interpret their output, then we will show how to use the evaluation scripts, and finally detail how each script functions."
      ],
      "metadata": {
        "id": "TWeYcdlM98vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data to train our classifiers\n",
        "\n",
        "[This](https://uncloud.univ-nantes.fr/index.php/s/OdAtErZgxKGjsNy) contains a bunch of symbols (in datasymbol_iso/) and expressions (in FullExpressions/) to help train our future classifiers.\n",
        "\n"
      ],
      "metadata": {
        "id": "DBWRfdGJNWoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Showcasing parts of code"
      ],
      "metadata": {
        "id": "1UbhDK12FT-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### segmenter.py explanation\n",
        "\n",
        "The first action is to collect the possible stroke combinations, for now we'll simply take every consecutive stroke combinations.  \n",
        "So if we have 4 strokes in one inkml file, 13 combinations can be done.  \n",
        "\n",
        "Each line of the output corresponds to a hypothesis: indicating the symbol type, the symbol with index (starting with 1, but dummy value for now since we don't know what symbol the combination could be), then the symbol without index, then the supposed confidence of the model. We also have the strokes used next to these informations.\n",
        "\n",
        "At this point, this can be optimized by already removed hypotheses take don't make sense, for instance trying to make a symbol with every single stroke is highly irregular and shouldn't happen, so we could remove that combination before calling the other scripts.\n",
        "\n",
        "The ground truth for the segmentation is available in the original lg files, since the strokes used are listed next to each symbol."
      ],
      "metadata": {
        "id": "YF6s8x3azFFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmenter.py -i ../data/formulaire001-equation001.inkml -o ../data/example.lg"
      ],
      "metadata": {
        "id": "6dPWrT0DBnCO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmenter.py -i ../data/formulaire001-equation001.inkml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV6ZMCZfP_Z2",
        "outputId": "eb3d0599-f70f-483b-f593-ed682dead159"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O,hyp0,*,1.0,0\n",
            "O,hyp1,*,1.0,1\n",
            "O,hyp2,*,1.0,2\n",
            "O,hyp3,*,1.0,3\n",
            "O,hyp4,*,1.0,4\n",
            "O,hyp5,*,1.0,0,1\n",
            "O,hyp6,*,1.0,1,2\n",
            "O,hyp7,*,1.0,2,3\n",
            "O,hyp8,*,1.0,3,4\n",
            "O,hyp9,*,1.0,0,1,2\n",
            "O,hyp10,*,1.0,1,2,3\n",
            "O,hyp11,*,1.0,2,3,4\n",
            "O,hyp12,*,1.0,0,1,2,3\n",
            "O,hyp13,*,1.0,1,2,3,4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we've said earlier, we simply keep every consecutive stroke combination as our possible hypotheses."
      ],
      "metadata": {
        "id": "wJBIb_1W7-E_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use this subsection when testing stuff for now"
      ],
      "metadata": {
        "id": "ScFP0M3SG8HL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git stash\n",
        "#!git stash drop"
      ],
      "metadata": {
        "id": "hhzXOe_FXkkE",
        "outputId": "f0b3f0bc-fe53-40be-b1b7-e4dcb1297c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No local changes to save\n",
            "No stash entries found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git reset --soft HEAD^ "
      ],
      "metadata": {
        "id": "cKE7XoYNduo9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git pull"
      ],
      "metadata": {
        "id": "Z1pRK30bFP7a",
        "outputId": "d5f30e8f-e583-4e68-bf44-abb167e7a23c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git config --global user.email \"XXX@gmail.com\"\n",
        "#!git config --global user.name \"XXX\""
      ],
      "metadata": {
        "id": "ODIimJvfFfov"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git add ."
      ],
      "metadata": {
        "id": "bCpa1mjKc4L3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git commit -m \"Speed up inference for segmentSelect and slightly modified AlexNet again\""
      ],
      "metadata": {
        "id": "yX9WK8T8c6FW",
        "outputId": "823a7006-3604-400d-bb73-a04c8cdd7412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main dc38065c7] Speed up inference for segmentSelect and slightly modified AlexNet again\n",
            " 4 files changed, 12 insertions(+), 17 deletions(-)\n",
            " rewrite code/output.png (94%)\n",
            " rewrite code/resultMLP.png (98%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git push https://hiddentoken@github.com/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation.git"
      ],
      "metadata": {
        "id": "9uUZDwxbdA9Q",
        "outputId": "aa05e69c-e241-4f0e-c6ed-a4d82dd3f36c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting objects: 7, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  14% (1/7)   \rCompressing objects:  28% (2/7)   \rCompressing objects:  42% (3/7)   \rCompressing objects:  57% (4/7)   \rCompressing objects:  71% (5/7)   \rCompressing objects:  85% (6/7)   \rCompressing objects: 100% (7/7)   \rCompressing objects: 100% (7/7), done.\n",
            "Writing objects:  14% (1/7)   \rWriting objects:  28% (2/7)   \rWriting objects:  42% (3/7)   \rWriting objects:  57% (4/7)   \rWriting objects:  71% (5/7)   \rWriting objects:  85% (6/7)   \rWriting objects: 100% (7/7)   \rWriting objects: 100% (7/7), 42.12 KiB | 21.06 MiB/s, done.\n",
            "Total 7 (delta 4), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation.git\n",
            "   357bb3271..dc38065c7  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CROHME_train_segmentSelector.py & segmentSelect.py explanation"
      ],
      "metadata": {
        "id": "JjTmdp150a1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we use neural networks in our overall process as our classifiers/predictors, they need to be trained beforehand. But let's first explain what we're trying to do in this part of the process:  \n",
        "\n",
        "The script 'segmentSelect.py' takes as input the initial inkml file, alongside the \"prototype\" lg file: We combine the stroke combinations from the prototype file alongside the inkml stroke data to generate images, then we check whether these images make sense as a symbol, no matter the context.  \n",
        "This is a classification problem with two possible outputs : Image is valid or invalid.  \n",
        "We also check the confidence value of the model with a threshold in order to ignore unsure hypotheses, which should boost accuracy somewhat.\n",
        "\n",
        "Now, for the training part, while we could simply store the weights of the models and import them, we still want to show the specifics of our training due to the characteristics of our data:\n",
        "\n",
        "While training the model batch per batch, we make sure that each of these batches contain an representative random subset of the original data, since we have a lot less invalid images for training than valid images, while still trying to make sure that the model doesn't excessively consider valid images.  \n",
        "The rest of the training logic is quite normal, the state of the model is saved whenever we achieve a new validation loss low, and we implemented early stopping to prevent overfitting."
      ],
      "metadata": {
        "id": "3GpG0BAV0c3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 CROHME_train_segmentSelector.py"
      ],
      "metadata": {
        "id": "DBL3xPInG-uD",
        "outputId": "c2baefed-fed4-4f46-aa0a-3355f5198bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "('invalid', 'valid')\n",
            "nb classes 2 , training size 12000, val size 4000, test size 4000\n",
            "invalid valid valid valid\n",
            "AlexNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4), bias=False)\n",
            "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(96, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 1 batch  1000 \n",
            "Train loss : 0.073\n",
            "Validation loss mean : 0.067\n",
            "Epoch 1 of 10 took 33.537s\n",
            "Epoch 2 batch   500 \n",
            "Train loss : 0.062\n",
            "Validation loss mean : 0.064\n",
            "Epoch 2 batch  1500 \n",
            "Train loss : 0.057\n",
            "Validation loss mean : 0.062\n",
            "Epoch 2 of 10 took 34.394s\n",
            "Epoch 3 batch  1000 \n",
            "Train loss : 0.054\n",
            "Validation loss mean : 0.058\n",
            "Epoch 3 of 10 took 32.261s\n",
            "Epoch 4 batch   500 \n",
            "Train loss : 0.052\n",
            "Validation loss mean : 0.057\n",
            "Epoch 4 batch  1500 \n",
            "Train loss : 0.048\n",
            "Validation loss mean : 0.056\n",
            "Epoch 4 of 10 took 34.357s\n",
            "Epoch 5 batch  1000 \n",
            "Train loss : 0.044\n",
            "Validation loss mean : 0.056\n",
            "Epoch 5 of 10 took 31.883s\n",
            "Epoch 6 batch   500 \n",
            "Train loss : 0.041\n",
            "Validation loss mean : 0.055\n",
            "Epoch 6 batch  1500 \n",
            "Train loss : 0.040\n",
            "Validation loss mean : 0.055\n",
            "Epoch 6 of 10 took 34.136s\n",
            "Epoch 7 batch  1000 \n",
            "Train loss : 0.037\n",
            "Validation loss mean : 0.055\n",
            "Epoch 7 of 10 took 31.790s\n",
            "Epoch 8 batch   500 \n",
            "Train loss : 0.035\n",
            "Validation loss mean : 0.054\n",
            "Epoch 8 batch  1500 \n",
            "Train loss : 0.033\n",
            "Validation loss mean : 0.055\n",
            "Epoch 8 of 10 took 34.044s\n",
            "Epoch 9 batch  1000 \n",
            "Train loss : 0.031\n",
            "Validation loss mean : 0.060\n",
            "Epoch 9 of 10 took 33.172s\n",
            "Epoch 10 batch   500 \n",
            "Train loss : 0.028\n",
            "Validation loss mean : 0.059\n",
            "Epoch 10 of 10 took 12.280s\n",
            "Warning: current epoch stopped early due to early stopping strategy\n",
            "Finished Training\n",
            "GroundTruth:  invalid invalid valid valid valid invalid valid invalid\n",
            "Predicted:  invalid invalid valid valid valid valid valid invalid\n",
            "Accuracy of the network on the test images: 82 %\n",
            "Accuracy of invalid : 75 % (1466/1952)\n",
            "Accuracy of valid : 86 % (1773/2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### segmentSelect.py example"
      ],
      "metadata": {
        "id": "m3W6Q2QxzNlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmentSelect.py -o ../data/example2.lg ../data/formulaire001-equation001.inkml ../data/example.lg "
      ],
      "metadata": {
        "id": "pv0w5wivD61i",
        "outputId": "fe3ff656-e1ab-4ea9-cc23-30c1dcd0bb46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"segmentSelect.py\", line 101, in <module>\n",
            "    main()\n",
            "  File \"segmentSelect.py\", line 87, in main\n",
            "    prob = computeProbSeg(traces, h, saveimg)\n",
            "  File \"segmentSelect.py\", line 55, in computeProbSeg\n",
            "    output = torch.nn.functional.softmax(model(im_tensor),dim=1)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/Master_2_MLVC_Recognize_Handwritten_Equation/code/modules.py\", line 55, in forward\n",
            "    out = self.layer1(x)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\", line 457, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\", line 453, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmentSelect.py ../data/formulaire001-equation001.inkml ../data/example.lg "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y60IqgVQBhP",
        "outputId": "2d266a04-4301-4f0f-931e-744b87aab695"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O,hyp1,*,0.7486852407455444,1\n",
            "O,hyp5,*,0.5107819437980652,0,1\n",
            "O,hyp6,*,0.6763725876808167,1,2\n",
            "O,hyp7,*,0.7221850752830505,2,3\n",
            "O,hyp8,*,0.9450982809066772,3,4\n",
            "O,hyp10,*,0.8999685645103455,1,2,3\n",
            "O,hyp11,*,0.5407421588897705,2,3,4\n",
            "O,hyp12,*,0.9287165403366089,0,1,2,3\n",
            "O,hyp13,*,0.8904486894607544,1,2,3,4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script takes as input the initial inkml file, alongside the \"prototype\" lg file: We combine the stroke combinations alongside the inkml data to generate images, then we check whether these make sense as a symbol, no matter the context.\n",
        "\n",
        "For now this simply gives a fully random probability that the images are valid symbols.\n",
        "\n",
        "Need to change two things in there, first adding a classifier to check the validity of supposed symbols,  \n",
        "then change the threshold based on empirical evidence or what I feel like at the time."
      ],
      "metadata": {
        "id": "1xt9xpt3FvIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### segmentReco.py explanation"
      ],
      "metadata": {
        "id": "b0AIEfy9CsB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 777 ./symbolReco.py"
      ],
      "metadata": {
        "id": "XR29Exa-Hfmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 symbolReco.py ../data/formulaire001-equation001.inkml ../data/bidule2.lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f18293-4618-4c86-87cc-5819ec7f5a56",
        "id": "duC2zf_nHfmu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O,hyp0,r,0.059779757207917304,0\n",
            "O,hyp0,geq,0.05030687013768514,0\n",
            "O,hyp1,2,0.05648836776140208,1\n",
            "O,hyp1,6,0.056168315175164935,1\n",
            "O,hyp1,8,0.05960923199570466,1\n",
            "O,hyp1,=,0.05475807870783242,1\n",
            "O,hyp1,geq,0.056816822917386364,1\n",
            "O,hyp3,f,0.0510902919404698,3\n",
            "O,hyp3,n,0.0586707731068381,3\n",
            "O,hyp3,u,0.053721497506933835,3\n",
            "O,hyp3,3,0.055092772863820916,3\n",
            "O,hyp4,b,0.05192545736402091,4\n",
            "O,hyp4,leq,0.07015718890027181,4\n",
            "O,hyp5,s,0.06121838413470821,0,1\n",
            "O,hyp5,A,0.050391613253440264,0,1\n",
            "O,hyp5,X,0.072619141223795,0,1\n",
            "O,hyp6,(,0.05046390880442578,1,2\n",
            "O,hyp7,p,0.06723378695795225,2,3\n",
            "O,hyp7,y,0.05172590875612772,2,3\n",
            "O,hyp7,1,0.05240988369270244,2,3\n",
            "O,hyp7,geq,0.058408507485593536,2,3\n",
            "O,hyp8,Z,0.053352030138174675,3,4\n",
            "O,hyp9,h,0.051727432180693006,0,1,2\n",
            "O,hyp9,C,0.05847255666598241,0,1,2\n",
            "O,hyp9,(,0.05560318869409104,0,1,2\n",
            "O,hyp9,geq,0.05338792763291579,0,1,2\n",
            "O,hyp10,r,0.055058494864859676,1,2,3\n",
            "O,hyp10,4,0.050618596960434595,1,2,3\n",
            "O,hyp11,c,0.05128946473017116,2,3,4\n",
            "O,hyp11,j,0.06079852247795053,2,3,4\n",
            "O,hyp11,w,0.05316091777564158,2,3,4\n",
            "O,hyp11,Y,0.05522000215632788,2,3,4\n",
            "O,hyp12,n,0.050532816195181345,0,1,2,3\n",
            "O,hyp13,E,0.06726193378991334,1,2,3,4\n",
            "O,hyp13,Y,0.05696633806544146,1,2,3,4\n",
            "O,hyp13,),0.06540731362648478,1,2,3,4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODOLIST: check that everything works: X  \n",
        "Apply evaluation script (import relevant things here): X  \n",
        "Nitpick a bunch of things:  X  \n",
        "Write some things on notebook: X  \n"
      ],
      "metadata": {
        "id": "lXmV8VSIvP3q"
      }
    }
  ]
}