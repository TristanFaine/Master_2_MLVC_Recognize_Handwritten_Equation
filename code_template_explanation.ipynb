{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSKAdz+7oT3xxx51Kv7leV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation/blob/main/code_template_explanation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task\n",
        "\n",
        "We were given InkML files, which contain metadata and a list of strokes:  \n",
        "[(0,0),(1;0)]...  \n",
        "These are on-line handwritten mathematical expressions, we'll try to recognize them by using a LG(Labelled Graph) as intermediate output.\n",
        "The sequence of actions will look like this for now:  \n",
        "1) Get each stroke  \n",
        "2) Convert each stroke to symbols (all possible combinations for now we'll optimize later)  \n",
        "Two strategies available: Consider only consecutive strokes, or allow X(1) number of \"time jumps\" for each possible symbol.  \n",
        "2.5) Make a classifier to ignore \"junk\" stroke combinations, such as a symbol created with every single stroke at the same time.  \n",
        "3) Classify each constructed symbol with a neural network.\n",
        "\n",
        "We'll handle spatial relations later  \n",
        "We'll also handle the final decision later, but we can add a grammar or language model at that point, "
      ],
      "metadata": {
        "id": "aWuEiNtvzSKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Environment setup"
      ],
      "metadata": {
        "id": "B9M5CzAi6gbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please import each file from the git repository to see how they work.  \n",
        "TODO: link from the git repo, should be feasible.\n",
        "\n",
        "Hiding my token for obvious reasons."
      ],
      "metadata": {
        "id": "aYodzelc6zQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://hiddentoken@github.com/TristanFaine/Master_2_MLVC_Recognize_Handwritten_Equation.git"
      ],
      "metadata": {
        "id": "jSZh0T12tA6_",
        "outputId": "e7c2a5f6-9301-4933-c256-ca515610f59f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Master_2_MLVC_Recognize_Handwritten_Equation'...\n",
            "remote: Enumerating objects: 119782, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 119782 (delta 29), reused 58 (delta 18), pack-reused 119711\u001b[K\n",
            "Receiving objects: 100% (119782/119782), 46.20 MiB | 4.69 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "Checking out files: 100% (209487/209487), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Master_2_MLVC_Recognize_Handwritten_Equation/code"
      ],
      "metadata": {
        "id": "8fBivD4utpW2",
        "outputId": "85882b0e-5127-4cd4-bca9-4a937cd786c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Master_2_MLVC_Recognize_Handwritten_Equation/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first try out each script then explain what they're supposed to do and how to interpret their output."
      ],
      "metadata": {
        "id": "TWeYcdlM98vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data to train our classifiers\n",
        "\n",
        "[This](https://uncloud.univ-nantes.fr/index.php/s/OdAtErZgxKGjsNy) contains a bunch of symbols (in datasymbol_iso/) and expressions (in FullExpressions/) to help train our future classifiers.\n",
        "\n",
        "#WARNING: training size\n",
        "there are a LOT of images in the CHROHME dataset, only use a subset to train our classifiers otherwise it'll take too long."
      ],
      "metadata": {
        "id": "DBWRfdGJNWoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##segmenter.py explanation"
      ],
      "metadata": {
        "id": "YF6s8x3azFFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 777 segmenter.py"
      ],
      "metadata": {
        "id": "qG2MP5Z1-For"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmenter.py -i ../data/formulaire001-equation001.inkml -o ../data/bidule.lg"
      ],
      "metadata": {
        "id": "6dPWrT0DBnCO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmenter.py -i ../data/formulaire001-equation001.inkml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV6ZMCZfP_Z2",
        "outputId": "bd596bef-95e0-41cf-c553-3a45c316dea8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O,hyp0,*,1.0,0\n",
            "O,hyp1,*,1.0,1\n",
            "O,hyp2,*,1.0,2\n",
            "O,hyp3,*,1.0,3\n",
            "O,hyp4,*,1.0,4\n",
            "O,hyp5,*,1.0,0,1\n",
            "O,hyp6,*,1.0,1,2\n",
            "O,hyp7,*,1.0,2,3\n",
            "O,hyp8,*,1.0,3,4\n",
            "O,hyp9,*,1.0,0,1,2\n",
            "O,hyp10,*,1.0,1,2,3\n",
            "O,hyp11,*,1.0,2,3,4\n",
            "O,hyp12,*,1.0,0,1,2,3\n",
            "O,hyp13,*,1.0,1,2,3,4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each line of this output corresponds to a hypothesis, we can ignore the first four values since they're dummy values indicating a symbol type thing, maybe the position, then the symbol with index, then the symbol without index, then the supposed confidence of our future model(s).. probably, then the strokes used to make that symbol.\n",
        "\n",
        "For now, we simply list every possible symbol, using every possible stroke in sequence, so if we have 4 strokes, we can make 13 possible symbols.  \n",
        "\n",
        "segmentSelect.py can be used to remove some hypotheses that don't make sense, for instance, the symbol that could be constructed with stroke [0,1,2,3,4] is highly unlikely to appear, so after training our classifier, we'd remove it.  \n",
        "Ground truth can be acquired from the lg files of the texts, since we have the strokes used as the 5th...i values."
      ],
      "metadata": {
        "id": "-6XdcfNlBrC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##segmentSelect.py explanation"
      ],
      "metadata": {
        "id": "m3W6Q2QxzNlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 777 code/segmentSelect.py"
      ],
      "metadata": {
        "id": "vCWmG7JzD61g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmentSelect.py -o ../data/bidule2.lg ../data/formulaire001-equation001.inkml ../data/bidule.lg "
      ],
      "metadata": {
        "id": "pv0w5wivD61i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 segmentSelect.py ../data/formulaire001-equation001.inkml ../data/bidule.lg "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y60IqgVQBhP",
        "outputId": "f71d97e6-7c32-446f-c163-ed195acad454"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the matrix obtained from convert_to_imgs\n",
            "<class 'numpy.matrix'>\n",
            "(32, 32)\n",
            "[[255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]]\n",
            "This is the matrix obtained after converting to tensor\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 32])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
            "         0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "This is the matrix obtained after converting to tensor differently\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([32, 32])\n",
            "tensor([[255, 255, 255,  ..., 255, 255, 255],\n",
            "        [255, 255, 255,  ..., 255, 255, 255],\n",
            "        [255, 255, 255,  ..., 255, 255, 255],\n",
            "        ...,\n",
            "        [255, 255, 255,  ..., 255, 255, 255],\n",
            "        [255, 255, 255,  ..., 255, 255, 255],\n",
            "        [255, 255, 255,  ..., 255, 255, 255]], dtype=torch.uint8)\n",
            "This is the matrix obtained when using dataloaders\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 1, 32, 32])\n",
            "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          ...,\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "          [1., 1., 1.,  ..., 1., 1., 1.]]]])\n",
            "Traceback (most recent call last):\n",
            "  File \"segmentSelect.py\", line 172, in <module>\n",
            "    main()\n",
            "  File \"segmentSelect.py\", line 160, in main\n",
            "    prob = computeProbSeg(traces, h, saveimg)\n",
            "  File \"segmentSelect.py\", line 129, in computeProbSeg\n",
            "    return float(model(im_tensor)[0][1])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/Master_2_MLVC_Recognize_Handwritten_Equation/code/modules.py\", line 11, in forward\n",
            "    x = x.view(-1, 32 * 32)\n",
            "RuntimeError: shape '[-1, 1024]' is invalid for input of size 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script takes as input the initial inkml file, alongside the \"prototype\" lg file: We combine the stroke combinations alongside the inkml data to generate images, then we check whether these make sense as a symbol, no matter the context.\n",
        "\n",
        "For now this simply gives a fully random probability that the images are valid symbols.\n",
        "\n",
        "Need to change two things in there, first adding a classifier to check the validity of supposed symbols,  \n",
        "then change the threshold based on empirical evidence or what I feel like at the time."
      ],
      "metadata": {
        "id": "1xt9xpt3FvIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##segmentReco.py explanation"
      ],
      "metadata": {
        "id": "b0AIEfy9CsB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 777 ./symbolReco.py"
      ],
      "metadata": {
        "id": "XR29Exa-Hfmt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 symbolReco.py ../data/formulaire001-equation001.inkml ../data/bidule2.lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f18293-4618-4c86-87cc-5819ec7f5a56",
        "id": "duC2zf_nHfmu"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O,hyp0,r,0.059779757207917304,0\n",
            "O,hyp0,geq,0.05030687013768514,0\n",
            "O,hyp1,2,0.05648836776140208,1\n",
            "O,hyp1,6,0.056168315175164935,1\n",
            "O,hyp1,8,0.05960923199570466,1\n",
            "O,hyp1,=,0.05475807870783242,1\n",
            "O,hyp1,geq,0.056816822917386364,1\n",
            "O,hyp3,f,0.0510902919404698,3\n",
            "O,hyp3,n,0.0586707731068381,3\n",
            "O,hyp3,u,0.053721497506933835,3\n",
            "O,hyp3,3,0.055092772863820916,3\n",
            "O,hyp4,b,0.05192545736402091,4\n",
            "O,hyp4,leq,0.07015718890027181,4\n",
            "O,hyp5,s,0.06121838413470821,0,1\n",
            "O,hyp5,A,0.050391613253440264,0,1\n",
            "O,hyp5,X,0.072619141223795,0,1\n",
            "O,hyp6,(,0.05046390880442578,1,2\n",
            "O,hyp7,p,0.06723378695795225,2,3\n",
            "O,hyp7,y,0.05172590875612772,2,3\n",
            "O,hyp7,1,0.05240988369270244,2,3\n",
            "O,hyp7,geq,0.058408507485593536,2,3\n",
            "O,hyp8,Z,0.053352030138174675,3,4\n",
            "O,hyp9,h,0.051727432180693006,0,1,2\n",
            "O,hyp9,C,0.05847255666598241,0,1,2\n",
            "O,hyp9,(,0.05560318869409104,0,1,2\n",
            "O,hyp9,geq,0.05338792763291579,0,1,2\n",
            "O,hyp10,r,0.055058494864859676,1,2,3\n",
            "O,hyp10,4,0.050618596960434595,1,2,3\n",
            "O,hyp11,c,0.05128946473017116,2,3,4\n",
            "O,hyp11,j,0.06079852247795053,2,3,4\n",
            "O,hyp11,w,0.05316091777564158,2,3,4\n",
            "O,hyp11,Y,0.05522000215632788,2,3,4\n",
            "O,hyp12,n,0.050532816195181345,0,1,2,3\n",
            "O,hyp13,E,0.06726193378991334,1,2,3,4\n",
            "O,hyp13,Y,0.05696633806544146,1,2,3,4\n",
            "O,hyp13,),0.06540731362648478,1,2,3,4\n",
            "\n"
          ]
        }
      ]
    }
  ]
}